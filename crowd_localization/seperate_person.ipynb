{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from scipy.interpolate import interp1d\n",
    "import imageio\n",
    "\n",
    "# Constants\n",
    "WIDTH = 1280\n",
    "HEIGHT = 720\n",
    "SCALE = 100\n",
    "FIXED_HEIGHT = 1.5\n",
    "FIXED_HEIGHT *= SCALE\n",
    "\n",
    "MAX_MISSED_FRAMES = 4\n",
    "COST_THRESHOLD = 300\n",
    "EDGE_BUFFER = 50\n",
    "\n",
    "BEV_WIDTH = 15\n",
    "BEV_HEIGHT = 10\n",
    "BOX_START = (0, 0)\n",
    "BOX_END = (15, 10)\n",
    "BEV_WIDTH *= SCALE\n",
    "BEV_HEIGHT *= SCALE\n",
    "BOX_START = (BOX_START[0] * SCALE, BOX_START[1] * SCALE)\n",
    "BOX_END = (BOX_END[0] * SCALE, BOX_END[1] * SCALE)\n",
    "BOX_WIDTH = BOX_END[0] - BOX_START[0]\n",
    "BOX_HEIGHT = BOX_END[1] - BOX_START[1]\n",
    "\n",
    "TEST_DATA_ID = '일도체육공원143'\n",
    "TEST_DATA_NAME = \"TS_2.시나리오_143.Outdoor_일도체육공원143(593)\"\n",
    "OUT_FILE_NAME = './saved_exp_results/' + TEST_DATA_ID + '_result.txt'\n",
    "IMG_FOLDER = '../ProcessedData/AIhub/images/Training/' + TEST_DATA_NAME + '/images'\n",
    "WAIT_TIME = 50\n",
    "\n",
    "SAVE_VISUALIZATION = True\n",
    "SAVE_FRAME = 352\n",
    "FPS = 6\n",
    "\n",
    "# World and image points\n",
    "world_points = np.array([\n",
    "    [0,0,0], [0.9, 0, 0], [5.05,0,0], [9.95,0,0], [14.1,0,0], \n",
    "    [15,0,0], [0,5.8,0], [5.05,5.8,0], [9.95,5.8,0], [15,5.8,0],\n",
    "    [7.5,0,3.05], [7.5,0,1.525], [7.5,5.8,0], [6, 9, 1.8], [5.2, 5.8, 1.6]\n",
    "], dtype=np.float32)\n",
    "world_points *= SCALE\n",
    "\n",
    "image_points = np.array([\n",
    "    [274, 307], [304, 307], [465, 304], [672, 302], [840, 302], \n",
    "    [877, 302], [113, 416], [392, 409], [711, 404], [1006, 397], \n",
    "    [564, 171], [564, 229], [547, 406], [420, 409], [517, 298]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Function to normalize 2D points\n",
    "def normalize_points_2d(points):\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    shifted_points = points - centroid\n",
    "    scale = np.sqrt(2) / np.mean(np.linalg.norm(shifted_points, axis=1))\n",
    "    normalization_matrix = np.array([\n",
    "        [scale, 0, -scale * centroid[0]],\n",
    "        [0, scale, -scale * centroid[1]],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    normalized_points = np.dot(normalization_matrix, np.vstack((points.T, np.ones((1, points.shape[0])))))\n",
    "    return normalized_points.T, normalization_matrix\n",
    "\n",
    "# Function to normalize 3D points\n",
    "def normalize_points_3d(points):\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    shifted_points = points - centroid\n",
    "    scale = np.sqrt(3) / np.mean(np.linalg.norm(shifted_points, axis=1))\n",
    "    normalization_matrix = np.array([\n",
    "        [scale, 0, 0, -scale * centroid[0]],\n",
    "        [0, scale, 0, -scale * centroid[1]],\n",
    "        [0, 0, scale, -scale * centroid[2]],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    normalized_points = np.dot(normalization_matrix, np.vstack((points.T, np.ones((1, points.shape[0])))))\n",
    "    return normalized_points.T, normalization_matrix\n",
    "\n",
    "# Function to compute homography matrix\n",
    "def compute_homography(src_points, dst_points):\n",
    "    A = []\n",
    "    for src, dst in zip(src_points, dst_points):\n",
    "        x, y, z = src[:3]\n",
    "        u, v = dst[:2]\n",
    "        A.append([-x, -y, -z, -1, 0, 0, 0, 0, u * x, u * y, u * z, u])\n",
    "        A.append([0, 0, 0, 0, -x, -y, -z, -1, v * x, v * y, v * z, v])\n",
    "    A = np.array(A)\n",
    "    U, S, Vh = np.linalg.svd(A)\n",
    "    L = Vh[-1, :] / Vh[-1, -1]\n",
    "    H = L.reshape(3, 4)\n",
    "    return H\n",
    "\n",
    "# Function to calculate homography matrix from world to image points\n",
    "def calculate_homography(world_points, image_points):\n",
    "    norm_world_points, T_world = normalize_points_3d(world_points)\n",
    "    norm_image_points, T_image = normalize_points_2d(image_points)\n",
    "    H_normalized = compute_homography(norm_world_points, norm_image_points)\n",
    "    H = np.dot(np.linalg.inv(T_image), np.dot(H_normalized, T_world))\n",
    "    return H\n",
    "\n",
    "# Function to calculate X, Y coordinates from u, v, Z using homography matrix\n",
    "def calculate_XY_from_uvZ(H, u, v, Z):\n",
    "    h11, h12, h13, h14 = H[0]\n",
    "    h21, h22, h23, h24 = H[1]\n",
    "    h31, h32, h33, h34 = H[2]\n",
    "    A = np.array([\n",
    "        [h11 - u * h31, h12 - u * h32],\n",
    "        [h21 - v * h31, h22 - v * h32]\n",
    "    ])\n",
    "    B = np.array([\n",
    "        [u * (h33 * Z + h34) - (h13 * Z + h14)],\n",
    "        [v * (h33 * Z + h34) - (h23 * Z + h24)]\n",
    "    ])\n",
    "    X, Y = np.linalg.solve(A, B).flatten()\n",
    "    return X, Y\n",
    "\n",
    "# Function to read data from file\n",
    "def read_data_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    return data\n",
    "\n",
    "# Function to calculate cost matrix for given positions\n",
    "def calculate_cost_matrix(prev_positions, curr_positions):\n",
    "    num_prev = len(prev_positions)\n",
    "    num_curr = len(curr_positions)\n",
    "    cost_matrix = np.zeros((num_prev, num_curr))\n",
    "    for i, prev_pos in enumerate(prev_positions):\n",
    "        for j, curr_pos in enumerate(curr_positions):\n",
    "            cost_matrix[i, j] = np.linalg.norm(np.array(prev_pos) - np.array(curr_pos))\n",
    "    return cost_matrix\n",
    "\n",
    "# Function to connect points based on smallest values in cost matrix first\n",
    "def connect_small_values_first(cost_matrix, threshold):\n",
    "    associations = []\n",
    "    num_prev, num_curr = cost_matrix.shape\n",
    "    used_prev = set()\n",
    "    used_curr = set()\n",
    "    while len(used_prev) < num_prev and len(used_curr) < num_curr:\n",
    "        min_value = np.inf\n",
    "        min_pos = (-1, -1)\n",
    "        for i in range(num_prev):\n",
    "            if i in used_prev:\n",
    "                continue\n",
    "            for j in range(num_curr):\n",
    "                if j in used_curr:\n",
    "                    continue\n",
    "                if cost_matrix[i, j] < min_value:\n",
    "                    min_value = cost_matrix[i, j]\n",
    "                    min_pos = (i, j)\n",
    "        if min_value >= threshold:\n",
    "            break\n",
    "        associations.append(min_pos)\n",
    "        used_prev.add(min_pos[0])\n",
    "        used_curr.add(min_pos[1])\n",
    "    return associations\n",
    "\n",
    "# Function to track objects over multiple frames based on distance threshold\n",
    "def track_objects(frame_data):\n",
    "    tracks = {}\n",
    "    missed_frames = {}\n",
    "    finished_tracks = {}\n",
    "    next_person_id = 0\n",
    "    for frame_idx, (frame_number, num_heads, positions) in enumerate(frame_data):\n",
    "        if frame_idx == 0:\n",
    "            for pos in positions:\n",
    "                tracks[next_person_id] = [(frame_number, pos)]\n",
    "                missed_frames[next_person_id] = 0\n",
    "                next_person_id += 1\n",
    "        else:\n",
    "            prev_positions = [track[-1][1] for track in tracks.values()]\n",
    "            prev_ids = list(tracks.keys())\n",
    "            cost_matrix = calculate_cost_matrix(prev_positions, positions)\n",
    "            associations = connect_small_values_first(cost_matrix, COST_THRESHOLD)\n",
    "            assigned_ids = set()\n",
    "            for i, j in associations:\n",
    "                person_id = prev_ids[i]\n",
    "                tracks[person_id].append((frame_number, positions[j]))\n",
    "                missed_frames[person_id] = 0\n",
    "                assigned_ids.add(person_id)\n",
    "            for person_id in list(tracks.keys()):\n",
    "                if person_id not in assigned_ids:\n",
    "                    missed_frames[person_id] += 1\n",
    "                    if missed_frames[person_id] > MAX_MISSED_FRAMES:\n",
    "                        if len(tracks[person_id]) == 1:\n",
    "                            del tracks[person_id]\n",
    "                            del missed_frames[person_id]\n",
    "                        else:\n",
    "                            finished_tracks[person_id] = tracks[person_id]\n",
    "                            del tracks[person_id]\n",
    "                            del missed_frames[person_id]\n",
    "            for j in range(len(positions)):\n",
    "                if j not in [assoc[1] for assoc in associations]:\n",
    "                    if positions[j][0] < EDGE_BUFFER or positions[j][0] > WIDTH - EDGE_BUFFER or positions[j][1] < EDGE_BUFFER or positions[j][1] > HEIGHT - EDGE_BUFFER:\n",
    "                        tracks[next_person_id] = [(frame_number, positions[j])]\n",
    "                        missed_frames[next_person_id] = 0\n",
    "                        next_person_id += 1\n",
    "                    else:\n",
    "                        tracks[next_person_id] = [(frame_number, positions[j])]\n",
    "                        missed_frames[next_person_id] = MAX_MISSED_FRAMES - 1\n",
    "                        next_person_id += 1\n",
    "    return {**tracks, **finished_tracks}\n",
    "\n",
    "# Function to interpolate missing data points in tracks\n",
    "def interpolate_missing_data(tracks):\n",
    "    interpolated_tracks = {}\n",
    "    for person_id, track in tracks.items():\n",
    "        frames = [pos[0] for pos in track]\n",
    "        positions = [pos[1] for pos in track]\n",
    "        frames_interp = np.arange(frames[0], frames[-1] + 1)\n",
    "        positions_x = [pos[0] for pos in positions]\n",
    "        positions_y = [pos[1] for pos in positions]\n",
    "        interp_x = interp1d(frames, positions_x, kind='linear', fill_value='extrapolate')\n",
    "        interp_y = interp1d(frames, positions_y, kind='linear', fill_value='extrapolate')\n",
    "        interpolated_positions = [(int(interp_x(frame)), int(interp_y(frame))) for frame in frames_interp]\n",
    "        interpolated_tracks[person_id] = list(zip(frames_interp, interpolated_positions))\n",
    "    return interpolated_tracks\n",
    "\n",
    "# Function to visualize head positions before perspective transformation\n",
    "def visualize_positions(frame_data, img_folder):\n",
    "    with imageio.get_writer(f'./saved_exp_results/{TEST_DATA_ID}_positions.gif', mode='I', fps=FPS, loop=0) as writer:\n",
    "        for frame_number, num_heads, positions in frame_data:\n",
    "            img_path = os.path.join(img_folder, f\"{frame_number}.jpg\")\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize((WIDTH, HEIGHT))\n",
    "            img = np.array(img)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            for pos in positions:\n",
    "                cv2.circle(img, pos, 10, (0, 255, 0), 2)\n",
    "            if SAVE_VISUALIZATION and frame_number == SAVE_FRAME:\n",
    "                Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)).save(f'./saved_exp_results/{TEST_DATA_ID}_position_screenshot.jpg')\n",
    "            writer.append_data(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            cv2.imshow('Head Positions', img)\n",
    "            if cv2.waitKey(WAIT_TIME) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Function to precompute the outside area mask and box lines for visualization\n",
    "def precompute_outside_area_and_box_lines(H):\n",
    "    pale_red = (204, 204, 255)\n",
    "    transformed_img = np.ones((BEV_HEIGHT, BEV_WIDTH, 3), dtype=np.uint8) * 255\n",
    "    outside_area_mask = np.zeros((BEV_HEIGHT, BEV_WIDTH), dtype=np.uint8)\n",
    "    for y in range(BOX_START[1], BOX_END[1]):\n",
    "        for x in range(BOX_START[0], BOX_END[0]):\n",
    "            U = np.dot(H, np.array([x, y, 0, 1]))\n",
    "            u, v = U[0] / U[2], U[1] / U[2]\n",
    "            if not (0 <= u < WIDTH and 0 <= v < HEIGHT):\n",
    "                outside_area_mask[y, x] = 1\n",
    "    box_corners = [BOX_START, (BOX_END[0], BOX_START[1]), BOX_END, (BOX_START[0], BOX_END[1])]\n",
    "    box_lines = []\n",
    "    for corner in box_corners:\n",
    "        X, Y = corner\n",
    "        U = np.dot(H, np.array([X, Y, 0, 1]))\n",
    "        u_trans, v_trans = U[0] / U[2], U[1] / U[2]\n",
    "        box_lines.append((int(u_trans), int(v_trans)))\n",
    "    return outside_area_mask, pale_red, box_lines\n",
    "\n",
    "# Function to visualize the tracks on images and transformed positions\n",
    "def visualize_tracks(tracks, frame_data, img_folder, H):\n",
    "    colors = [(255, 128, 128), (128, 255, 128), (128, 128, 255), (255, 255, 128), \n",
    "              (255, 128, 255), (128, 255, 255), (192, 192, 128), (128, 192, 192)]\n",
    "    outside_area_mask, pale_red, box_lines = precompute_outside_area_and_box_lines(H)\n",
    "    frame_dict = {frame_number: positions for frame_number, num_heads, positions in frame_data}\n",
    "    visualization_img = np.ones((BEV_HEIGHT, BEV_WIDTH, 3), dtype=np.uint8) * 255\n",
    "    visualization_img[outside_area_mask == 1] = pale_red[::-1]\n",
    "    \n",
    "    with imageio.get_writer(f'./saved_exp_results/{TEST_DATA_ID}_tracks_original.gif', mode='I', fps=FPS, loop=0) as writer_original, \\\n",
    "         imageio.get_writer(f'./saved_exp_results/{TEST_DATA_ID}_tracks_transformed.gif', mode='I', fps=FPS, loop=0) as writer_transformed:\n",
    "    \n",
    "        for frame_number in sorted(frame_dict.keys()):\n",
    "            img_path = os.path.join(img_folder, f\"{frame_number}.jpg\")\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize((WIDTH, HEIGHT))\n",
    "            img = np.array(img)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            transformed_img = np.ones((BEV_HEIGHT, BEV_WIDTH, 3), dtype=np.uint8) * 255\n",
    "            cv2.line(img, box_lines[0], box_lines[1], (0, 0, 255), 2)\n",
    "            cv2.line(img, box_lines[1], box_lines[2], (0, 0, 255), 2)\n",
    "            cv2.line(img, box_lines[2], box_lines[3], (0, 0, 255), 2)\n",
    "            cv2.line(img, box_lines[3], box_lines[0], (0, 0, 255), 2)\n",
    "            for person_id, track in tracks.items():\n",
    "                for track_frame_number, pos in track:\n",
    "                    if track_frame_number == frame_number and pos != (-1, -1):\n",
    "                        u, v = pos\n",
    "                        color = colors[person_id % len(colors)]\n",
    "                        cv2.circle(transformed_img, (int(u), int(v)), 10, color, -1)\n",
    "                        cv2.circle(transformed_img, (int(u), int(v)), 10, (0, 0, 0), 2)\n",
    "                        cv2.putText(transformed_img, str(person_id), (int(u) + 15, int(v) + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "                        X, Y, Z = pos[0], pos[1], FIXED_HEIGHT\n",
    "                        U = np.dot(H, np.array([X, Y, Z, 1]))\n",
    "                        u_trans, v_trans = U[0] / U[2], U[1] / U[2]\n",
    "                        cv2.circle(img, (int(u_trans), int(v_trans)), 10, color, 2)\n",
    "                        cv2.putText(img, str(person_id), (int(u_trans) + 15, int(v_trans) + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "            transformed_img[outside_area_mask == 1] = pale_red\n",
    "            transformed_img = transformed_img[BOX_START[1]:BOX_END[1], BOX_START[0]:BOX_END[0]]\n",
    "            if SAVE_VISUALIZATION and frame_number == SAVE_FRAME:\n",
    "                Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)).save(f'./saved_exp_results/{TEST_DATA_ID}_track_screenshot.jpg')\n",
    "                Image.fromarray(cv2.cvtColor(transformed_img, cv2.COLOR_BGR2RGB)).save(f'./saved_exp_results/{TEST_DATA_ID}_track_transformed_screenshot.jpg')\n",
    "            writer_original.append_data(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            writer_transformed.append_data(cv2.cvtColor(transformed_img, cv2.COLOR_BGR2RGB))\n",
    "            img = cv2.resize(img, (WIDTH // 2, HEIGHT // 2)) \n",
    "            transformed_img = cv2.resize(transformed_img, (BOX_WIDTH // 2, BOX_HEIGHT // 2))\n",
    "            cv2.imshow('Tracked Heads - Original', img)\n",
    "            cv2.moveWindow('Tracked Heads - Original', 0, 0)\n",
    "            cv2.imshow('Tracked Heads - Transformed', transformed_img)\n",
    "            cv2.moveWindow('Tracked Heads - Transformed', WIDTH // 2, 0)\n",
    "            if cv2.waitKey(WAIT_TIME) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    if SAVE_VISUALIZATION:\n",
    "        visualization_img = visualization_img[BOX_START[1]:BOX_END[1], BOX_START[0]:BOX_END[0]]\n",
    "        visualization_pil_img = Image.fromarray(visualization_img)\n",
    "        draw = ImageDraw.Draw(visualization_pil_img)\n",
    "        font = ImageFont.load_default()\n",
    "        for person_id, track in tracks.items():\n",
    "            for i in range(1, len(track)):\n",
    "                start_point = track[i-1][1]\n",
    "                end_point = track[i][1]\n",
    "                draw.line([start_point, end_point], fill=colors[person_id % len(colors)], width=2)\n",
    "                mid_point = ((start_point[0] + end_point[0]) // 2, (start_point[1] + end_point[1]) // 2)\n",
    "                draw.text(mid_point, str(person_id), fill=(0, 0, 0), font=font)\n",
    "        visualization_pil_img.save(f'./saved_exp_results/{TEST_DATA_ID}_track_visualization.jpg')\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    data = read_data_from_file(OUT_FILE_NAME)\n",
    "    frame_data = []\n",
    "    transformed_frame_data = []\n",
    "    H = calculate_homography(world_points, image_points)\n",
    "    for line in data:\n",
    "        parts = list(map(int, line.split()))\n",
    "        frame_number = parts[0]\n",
    "        num_heads = parts[1]\n",
    "        positions = [(parts[i], parts[i + 1]) for i in range(2, len(parts), 2)]\n",
    "        transformed_positions = [calculate_XY_from_uvZ(H, pos[0], pos[1], FIXED_HEIGHT) for pos in positions]\n",
    "        frame_data.append((frame_number, num_heads, positions))\n",
    "        transformed_frame_data.append((frame_number, num_heads, transformed_positions))\n",
    "    visualize_positions(frame_data, IMG_FOLDER)\n",
    "    tracks = track_objects(transformed_frame_data)\n",
    "    # interpolated_tracks = interpolate_missing_data(tracks)\n",
    "    visualize_tracks(tracks, frame_data, IMG_FOLDER, H)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[517, 298]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# List to store click positions\n",
    "click_positions = []\n",
    "\n",
    "# Define the mouse callback function\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        click_positions.append([x, y])\n",
    "        cv2.circle(open_cv_image, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.putText(open_cv_image, str(len(click_positions)), (x + 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Image\", open_cv_image)\n",
    "\n",
    "# Read the image using PIL\n",
    "image_path = \"../ProcessedData/AIhub/images/Training/\" + TEST_DATA_NAME + \"/images/360.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Resize the image\n",
    "resized_image = image.resize((1280, 720))\n",
    "\n",
    "# Convert the resized image to OpenCV format\n",
    "open_cv_image = cv2.cvtColor(np.array(resized_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "# Create a window and set the mouse callback function\n",
    "cv2.namedWindow(\"Image\")\n",
    "cv2.setMouseCallback(\"Image\", mouse_callback)\n",
    "\n",
    "# Show the image\n",
    "cv2.imshow(\"Image\", open_cv_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(click_positions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IIM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
